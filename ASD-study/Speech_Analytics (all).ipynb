{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Analysis\n",
    "import os\n",
    "import sys\n",
    "print (os.getcwd())\n",
    "sys.path.append('/home/Hanna.Drimalla/ml-autism/scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import scipy\n",
    "#import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import imageio\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import scale\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "import mycharite\n",
    "import mystats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, df_audio, action_r, action_c, gaze, audio =mycharite.load('charite')\n",
    "df_audio['asc']=(df_audio.asd==11)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_audio=df_audio.rename(columns={'0' : 'spectrum_0', '1': 'spectrum_1', '2': 'spectrum_2', \n",
    "                      '3' : 'spectrum_3', '4': 'spectrum_4', '5': 'spectrum_5',\n",
    "                      '6' : 'spectrum_6', '7': 'spectrum_7', '8': 'spectrum_8',\n",
    "                      '9' : 'spectrum_9', '10': 'spectrum_10', '11': 'spectrum_11',\n",
    "                      '12' : 'spectrum_12', '13': 'spectrum_13', '14': 'spectrum_14',\n",
    "                      '15' : 'spectrum_15', '16': 'spectrum_16', '17': 'spectrum_17',\n",
    "                      '18' : 'spectrum_18', '19': 'spectrum_19', '20': 'spectrum_20',\n",
    "                      '21' : 'spectrum_21', '22': 'spectrum_22', '23': 'spectrum_23',\n",
    "                      '24': 'spectrum_24', '25' : 'spectrum_25', '26': 'spectrum_26', \n",
    "                      '27': 'spectrum_27', '28' : 'spectrum_28', '29': 'spectrum_29',\n",
    "                      '30': 'spectrum_30', '31' : 'spectrum_31', '32': 'spectrum_32', \n",
    "                      '33': 'spectrum_33',  '34' : 'spectrum_34', '35': 'spectrum_35',\n",
    "                      '36': 'spectrum_36',  '37' : 'spectrum_37', '38': 'spectrum_38', \n",
    "                      '39': 'spectrum_39'                          \n",
    "          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_audio.columns\n",
    "df_audio=df_audio.rename(columns={'disgust_proband': 'disgust_participant', \n",
    "                      'neutral_proband' : 'neutral_participant', \n",
    "                          'joy_proband': 'joy_participant'\n",
    "                      })\n",
    "\n",
    "df_audio=mycharite.adapt_times(df_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_audio['participant_speaks']=(df_audio.conversation=='joy_participant') | (df_audio.conversation=='disgust_participant') | (df_audio.conversation=='neutral_proband')#if conversation==\n",
    "df_audio=df_audio[(df_audio.participant_speaks==True)&(df_audio.conversation!='intro')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=['pitch', 'localJitter', 'localabsoluteJitter', 'rapJitter', 'ppq5Jitter',\n",
    "   'ddpJitter', 'localShimmer', 'localdbShimmer', 'apq3Shimmer',\n",
    "   'apq5Shimmer', 'apq11Shimmer', 'ddaShimmer', 'JitterPCA', 'ShimmerPCA']\n",
    "\n",
    "\n",
    "for i in var:\n",
    "    print (i)\n",
    "    print (df_audio.groupby('vpn').mean().groupby(['asc'])[i].describe())\n",
    "    \n",
    "    \n",
    "var=['meanF0Hz', 'stdevF0Hz', 'HNR']\n",
    "\n",
    "\n",
    "for i in var:\n",
    "    print (i)\n",
    "    print (df_audio.groupby('vpn').mean().groupby(['asc', 'sex_x'])[i].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spectrogram_one(df_audio):\n",
    "    data=np.array(df_audio.groupby('timestamp').mean()[audio].T)\n",
    "    ax = sns.heatmap(data)\n",
    "    plt.show()\n",
    "    \n",
    "def spectrogram(df_audio, name):\n",
    "    plt.close()\n",
    "    data=(df_audio.groupby('asc').mean()[audio[3:14]].T)\n",
    "    #mfccs = sklearn.preprocessing.scale(data, axis=0)\n",
    "    print (data)\n",
    "    ax = sns.heatmap(np.array(data)) #, vmin=-2, vmax=2)\n",
    "    plt.savefig('Heatmap' + name +'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_comparison(df):\n",
    "    var=['pitch','meanF0Hz', 'stdevF0Hz', 'HNR',\n",
    "       'localJitter', 'localabsoluteJitter', 'rapJitter', 'ppq5Jitter',\n",
    "       'ddpJitter', 'localShimmer', 'localdbShimmer', 'apq3Shimmer',\n",
    "       'apq5Shimmer', 'apq11Shimmer', 'ddaShimmer', 'JitterPCA', 'ShimmerPCA']\n",
    "\n",
    "    for i in var:\n",
    "        print (i)\n",
    "        df1=df[df.asc==0].groupby('vpn').mean()\n",
    "        df2=df[df.asc==1].groupby('vpn').mean()\n",
    "        mystats.two_ind_sample_tests(df1, df2, i)\n",
    "        \n",
    "group_comparison(df_audio[df_audio.conversation!='intro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_comparison(df_audio[df_audio.sex_x==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_comparison(df_audio[df_audio.sex_x==2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_comparison_median(df):\n",
    "    var=['pitch','meanF0Hz', 'stdevF0Hz', 'HNR',\n",
    "       'localJitter', 'localabsoluteJitter', 'rapJitter', 'ppq5Jitter',\n",
    "       'ddpJitter', 'localShimmer', 'localdbShimmer', 'apq3Shimmer',\n",
    "       'apq5Shimmer', 'apq11Shimmer', 'ddaShimmer', 'JitterPCA', 'ShimmerPCA']\n",
    "\n",
    "    for i in var:\n",
    "        print (i)\n",
    "        df1=df[df.asc==0].groupby('vpn').median()\n",
    "        df2=df[df.asc==1].groupby('vpn').median()\n",
    "        mystats.two_ind_sample_tests(df1, df2, i)\n",
    "        df1=df[df.asc==0].groupby('vpn').median()\n",
    "        df2=df[df.asc==1].groupby('vpn').median()\n",
    "        \n",
    "group_comparison_median(df_audio[df_audio.conversation!='intro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_comparison_median(df_audio[df_audio.sex_x==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_comparison_median(df_audio[df_audio.sex_x==2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "def eta_squared(aov):\n",
    "    aov['eta_sq'] = 'NaN'\n",
    "    aov['eta_sq'] = aov[:-1]['sum_sq']/sum(aov['sum_sq'])\n",
    "    return aov\n",
    " \n",
    "def omega_squared(aov):\n",
    "    mse = aov['sum_sq'][-1]/aov['df'][-1]\n",
    "    aov['omega_sq'] = 'NaN'\n",
    "    aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df']*mse))/(sum(aov['sum_sq'])+mse)\n",
    "    return aov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=['pitch','meanF0Hz', 'stdevF0Hz', 'HNR',\n",
    "       'localJitter', 'localabsoluteJitter', 'rapJitter', 'ppq5Jitter',\n",
    "       'ddpJitter', 'localShimmer', 'localdbShimmer', 'apq3Shimmer',\n",
    "       'apq5Shimmer', 'apq11Shimmer', 'ddaShimmer', 'JitterPCA', 'ShimmerPCA']\n",
    "\n",
    "#PITCH IS ENERGY\n",
    "\n",
    "formula = 'HNR ~ C(sex_x) + C(asc)'\n",
    "model = ols(formula, df_audio.groupby('vpn').median()).fit()\n",
    "aov_table = anova_lm(model, typ=2)\n",
    "eta_squared(aov_table)\n",
    "omega_squared(aov_table)\n",
    "print(aov_table)\n",
    "\n",
    "\n",
    "formula = 'meanF0Hz ~ C(sex_x) + C(asc)'\n",
    "model = ols(formula, df_audio.groupby('vpn').mean()).fit()\n",
    "aov_table = anova_lm(model, typ=2)\n",
    "eta_squared(aov_table)\n",
    "omega_squared(aov_table)\n",
    "print(aov_table)\n",
    "\n",
    "\n",
    "formula = 'stdevF0Hz ~ C(sex_x) + C(asc)'\n",
    "model = ols(formula, df_audio.groupby('vpn').mean()).fit()\n",
    "aov_table = anova_lm(model, typ=2)\n",
    "eta_squared(aov_table)\n",
    "omega_squared(aov_table)\n",
    "print(aov_table)\n",
    "\n",
    "formula = 'localabsoluteJitter ~ C(sex_x) + C(asc)'\n",
    "model = ols(formula, df_audio.groupby('vpn').mean()).fit()\n",
    "aov_table = anova_lm(model, typ=2)\n",
    "eta_squared(aov_table)\n",
    "omega_squared(aov_table)\n",
    "print(aov_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_audio['sex']=df_audio.sex_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "for i in audio:\n",
    "    print (i)\n",
    "    plt.hist(((df_audio[df_audio.asc==0].groupby('vpn').mean()[i])))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y, sr = librosa.load(audio_file, sr=None) // sr is none so librosa can sample the audion using the convenient sr\n",
    "mfccs = librosa.feature.mfcc(y, sr, n_mfcc=13, hop_length=int(0.010sr), n_fft=int(0.025sr))\n",
    "-To set the width of window to 25 ms you have tu multiply the sr and 0.025.The reason behind that is that sr is the number of samples in one second. so to get the number of samples in 25ms you have to multiply by 0.025.\n",
    "-same thing for the stride, to get a stride of 10 ms, you need to multiply the sr and 0.010."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
